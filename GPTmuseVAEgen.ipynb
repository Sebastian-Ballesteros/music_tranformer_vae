{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianballesteros/Desktop/ie_classes/Semester_7/Advanced_AI/group_project_final/GPfinalvenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from GPTmuseVAE import GPTmuseVAE\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from GPTmuseVAE import GPTmuseVAE\n",
    "from miditok.pytorch_data import DatasetTok\n",
    "from miditok import REMI\n",
    "from torchtoolkit.data import create_subsets\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "import pygame\n",
    "from pygame import mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "block_size = 124 # what is the maximum context length for predictions?\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: midi_dataset_tokens_no_bpe/midi_metal/Slayer:   0%|          | 0/511 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: midi_dataset_tokens_no_bpe/midi_metal/Slayer: 100%|██████████| 511/511 [00:02<00:00, 231.46it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = REMI(params= Path('midi_dataset_tokenizer_bpe.conf'))\n",
    "vocab_size = len(tokenizer)\n",
    "\n",
    "tokens_paths = list(Path('midi_dataset_tokens_no_bpe').glob(\"**/*.json\"))\n",
    "\n",
    "dataset = DatasetTok(\n",
    "    tokens_paths, \n",
    "    max_seq_len=block_size, # to make target and prediction match the song length of block size\n",
    "    min_seq_len=block_size, \n",
    "    one_token_stream= False,\n",
    "    func_to_get_labels = get_artist_label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.166608 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = GPTmuseVAE( vocab_size= len(tokenizer),\n",
    "                    n_embd = 32,\n",
    "                    n_head = 4,\n",
    "                    n_layer = 2,\n",
    "                    z_dim = 32,\n",
    "                    block_size = block_size,\n",
    "                    dropout = 0.2)\n",
    "\n",
    "\n",
    "m = model.to(device)\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_state_dict = torch.load('checkpoints/checkpoint_3900.pt')\n",
    "model.load_state_dict(loaded_state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4, 137, 198,   4,   4, 153,  20, 108, 118,  22, 108, 118,  33, 108,\n",
       "         118, 161,  20, 108, 118,  22, 108, 118,  33, 108, 118,   4,   4,   4,\n",
       "         137,  29, 108, 118, 139,  29, 108, 118, 141,  29, 108, 118,   4, 153,\n",
       "          20, 108, 118,  22, 108, 118,  33, 108, 118, 161,  20, 108, 118,  22,\n",
       "         108, 118,  33, 108, 118,   4, 165,  22, 108, 118, 167,  22, 108, 118,\n",
       "           4, 137,  20, 108, 118,  33, 108, 118, 139,  22, 108, 118, 141,  22,\n",
       "         108, 118, 143,  22, 108, 118, 145,  29, 108, 118, 147,  29, 108, 118,\n",
       "         149,  22, 108, 118, 151,  22, 108, 118, 153,  22, 108, 118, 155,  29,\n",
       "         108, 118, 157,  29, 108, 118, 159,  29, 108, 118, 161,  25],\n",
       "        [108, 118, 163,  25, 108, 118, 165,  25, 108, 118, 167,  25, 108, 118,\n",
       "           4, 137,  20, 108, 118,  33, 108, 118, 139,  20, 108, 118, 141,  22,\n",
       "         108, 118,  30, 108, 118, 145,  20, 108, 118, 147,  20, 108, 118, 149,\n",
       "          22, 108, 118,  30, 108, 118, 153,  20, 108, 118, 155,  20, 108, 118,\n",
       "         157,  22, 108, 118,  30, 108, 118, 161,  20, 108, 118, 163,  20, 108,\n",
       "         118, 165,  22, 108, 118,  30, 108, 118,   4, 137,  20, 108, 118, 139,\n",
       "          20, 108, 118, 141,  22, 108, 118,  30, 108, 118, 145,  20, 108, 118,\n",
       "         147,  20, 108, 118, 149,  22, 108, 118,  30, 108, 118, 153,  20, 108,\n",
       "         118, 155,  20, 108, 118, 157,  22, 108, 118,  30, 108, 118]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_seed = torch.stack(dataset[0:2]['input_ids'])\n",
    "gen_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 252])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "generated_sequence = model.generate(gen_seed[:20], max_new_tokens=128)\n",
    "print(generated_sequence[0].shape)\n",
    "out = generated_sequence[0].cpu().numpy().tolist()\n",
    "print(len(out))\n",
    "gen_midi = tokenizer.tokens_to_midi(out)\n",
    "gen_midi.dump('musicGPT.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "mixer.music.load(\"musicGPT.mid\")\n",
    "mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.music.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , small_data = create_subsets(dataset, [0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, labels = process_dataset_for_z(small_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Slayer': 0,\n",
       " 'Judas Priest': 1,\n",
       " 'Black_sabath': 2,\n",
       " 'Pantera': 3,\n",
       " 'Ozzy Osbourne': 4,\n",
       " 'Sepultura': 5,\n",
       " 'Children Of Bodom': 6,\n",
       " 'Carcass': 7,\n",
       " 'Megadeth': 8,\n",
       " 'Type O Negative': 9,\n",
       " 'midi_pop_songs': 10,\n",
       " 'Mozart': 11,\n",
       " 'Ravel': 12,\n",
       " 'Dvorak': 13,\n",
       " 'Beethoven': 14,\n",
       " 'Haydn': 15,\n",
       " 'Schubert': 16,\n",
       " 'Cambini': 17,\n",
       " 'Bach': 18,\n",
       " 'Brahms': 19,\n",
       " 'Faure': 20}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_artist_label.artist_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer_dict = calculate_feature_pointers(z,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Beethoven', 'Children Of Bodom', 'Cambini', 'Schubert', 'Sepultura', 'Carcass', 'Slayer', 'midi_pop_songs', 'Brahms', 'Ravel', 'Judas Priest', 'Megadeth', 'Black_sabath', 'Ozzy Osbourne', 'Faure', 'Pantera', 'Dvorak', 'Bach', 'Haydn', 'Mozart', 'Type O Negative'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointer_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = pointer_dict['Dvorak']\n",
    "magnitude = 1\n",
    "pointer = pointer.tile(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magnitude 1\n",
      "z_vector tensor([ 8.0658, -4.8176,  2.3943, -3.2991,  6.9716,  1.0544,  7.8009, -8.0771,\n",
      "         3.0934,  4.1215,  3.4642, -4.1732,  3.0921,  7.7531,  0.2165,  2.2996,\n",
      "        -2.2709, 11.2617,  3.3499, -4.2135,  3.9536,  3.3372,  9.7705, -3.3861,\n",
      "        -1.2279,  4.3181,  2.6494, -2.6907, -1.4028,  2.9462,  8.1385, -1.6483,\n",
      "        -6.3669,  5.8235,  4.6581, -3.5691,  3.3750,  2.4097,  0.8522,  4.2377,\n",
      "        -4.7078,  4.1051,  4.5070,  9.7888, -8.0963,  2.5936,  7.5204,  1.5311,\n",
      "        -6.6679,  4.4963,  8.1422,  0.2520, -9.7220,  8.2531, -1.3385,  9.3462,\n",
      "        -7.0001,  8.3142,  1.9845, 11.4923, -4.7780,  2.9750,  6.6355,  4.6584,\n",
      "        -1.2829,  3.4960, -1.7008,  7.3620, -3.9086,  7.1093, -0.7029,  2.4259,\n",
      "         7.5590, -3.9390, -2.0379,  9.5034, -0.2200, -7.1290,  3.1868,  2.9409,\n",
      "        -3.9810,  1.1169,  2.1267,  1.8067,  6.5382, -6.2372,  3.8690,  2.6369,\n",
      "         3.1495, -1.8014,  7.3941, -1.4862, 10.2907, -6.2188,  7.7997,  0.2584,\n",
      "         4.3645, -8.5683, 13.8681, -4.8379,  6.9545,  0.2276,  4.6105, -2.5073,\n",
      "         4.0356,  3.3210, -0.9854, -3.0430,  5.0763, -2.3652,  8.2550, -1.4060,\n",
      "         3.7247,  3.8239,  5.1342, -5.4563,  9.3948,  2.5993,  3.3210, -2.3977,\n",
      "         9.4613,  5.1891, -5.5756])\n",
      "z tensor([[ 0.4222,  0.2328, -2.2787,  ...,  0.5998, -1.7217, -0.1429],\n",
      "        [-0.4020, -1.1581,  0.5343,  ..., -1.8316, -0.6503, -0.0629],\n",
      "        [ 1.1174, -0.6356, -1.3997,  ...,  1.1626, -0.1827, -0.0062],\n",
      "        ...,\n",
      "        [-1.1015, -1.8066, -1.6441,  ..., -0.0336, -0.0658, -1.5102],\n",
      "        [-1.1526, -0.0590, -0.3064,  ..., -1.7403,  0.8385,  0.2267],\n",
      "        [ 0.6255, -0.1089, -1.0713,  ..., -0.5194,  0.5989, -1.7796]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (123) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/sebastianballesteros/Desktop/ie_classes/Semester_7/Advanced_AI/group_project_final/GPTmuseVAEgen.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sebastianballesteros/Desktop/ie_classes/Semester_7/Advanced_AI/group_project_final/GPTmuseVAEgen.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mgenerate(gen_seed ,max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, latent_vector\u001b[39m=\u001b[39;49mpointer, magnitude\u001b[39m=\u001b[39;49m magnitude)\n",
      "File \u001b[0;32m~/Desktop/ie_classes/Semester_7/Advanced_AI/group_project_final/GPTmuseVAE.py:182\u001b[0m, in \u001b[0;36mGPTmuseVAE.generate\u001b[0;34m(self, idx, max_new_tokens, latent_vector, magnitude)\u001b[0m\n\u001b[1;32m    180\u001b[0m idx_cond \u001b[39m=\u001b[39m idx[:, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock_size:]\n\u001b[1;32m    181\u001b[0m \u001b[39m# get the predictions\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m logits, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(idx_cond, targets \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m, latent_vector \u001b[39m=\u001b[39;49m latent_vector, magnitude \u001b[39m=\u001b[39;49m magnitude)\n\u001b[1;32m    183\u001b[0m \u001b[39m# focus only on the last time step\u001b[39;00m\n\u001b[1;32m    184\u001b[0m logits \u001b[39m=\u001b[39m logits[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :] \u001b[39m# becomes (B, C)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ie_classes/Semester_7/Advanced_AI/group_project_final/GPfinalvenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ie_classes/Semester_7/Advanced_AI/group_project_final/GPfinalvenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ie_classes/Semester_7/Advanced_AI/group_project_final/GPTmuseVAE.py:157\u001b[0m, in \u001b[0;36mGPTmuseVAE.forward\u001b[0;34m(self, idx, targets, latent_vector, magnitude, device)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m## Incorporate vae here VAE (x,z_vector,magnitude)\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m latent_vector \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     x, mu, logvar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvae\u001b[39m.\u001b[39;49mforward_z(x, latent_vector, magnitude)\n\u001b[1;32m    159\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     x, mu, logvar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvae\u001b[39m.\u001b[39mforward(x)\n",
      "File \u001b[0;32m~/Desktop/ie_classes/Semester_7/Advanced_AI/group_project_final/GPTmuseVAE.py:44\u001b[0m, in \u001b[0;36mVAE.forward_z\u001b[0;34m(self, x, z_vector, magnitude)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mz_vector\u001b[39m\u001b[39m'\u001b[39m,z_vector)\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mz\u001b[39m\u001b[39m'\u001b[39m,z)\n\u001b[0;32m---> 44\u001b[0m z \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49m (magnitude \u001b[39m*\u001b[39;49m z_vector)\n\u001b[1;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(z\u001b[39m.\u001b[39mview(B, T, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)), mu, logvar\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (123) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model.generate(gen_seed ,max_new_tokens=128, latent_vector=pointer, magnitude= magnitude)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
