{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianballesteros/Desktop/ie_classes/Semester_7/Advanced_AI/group_project_final/GPfinalvenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from GPTmuseVAE import GPTmuseVAE\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from GPTmuseVAE import GPTmuseVAE\n",
    "from miditok.pytorch_data import DatasetTok\n",
    "from miditok import REMI\n",
    "from torchtoolkit.data import create_subsets\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "import pygame\n",
    "from pygame import mixer\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "n_embd = 64\n",
    "n_head = 8\n",
    "n_layer = 4\n",
    "z_dim = 16\n",
    "block_size = 254 # what is the maximum context length for predictions?\n",
    "dropout = 0.2\n",
    "########################\n",
    "\n",
    "# Hyperparameters\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Tokenized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: midi_dataset_tokens_no_bpe/midi_metal/Slayer:   0%|          | 0/511 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: midi_dataset_tokens_no_bpe/midi_metal/Slayer: 100%|██████████| 511/511 [00:01<00:00, 259.20it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = REMI(params= Path('midi_dataset_tokenizer_bpe.conf'))\n",
    "vocab_size = len(tokenizer)\n",
    "\n",
    "tokens_paths = list(Path('midi_dataset_tokens_no_bpe').glob(\"**/*.json\"))\n",
    "\n",
    "dataset = DatasetTok(\n",
    "    tokens_paths, \n",
    "    max_seq_len=block_size, # to make target and prediction match the song length of block size\n",
    "    min_seq_len=block_size, \n",
    "    one_token_stream= False,\n",
    "    func_to_get_labels = get_artist_label\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.481936 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = GPTmuseVAE( vocab_size= len(tokenizer),\n",
    "                    n_embd = n_embd,\n",
    "                    n_head = n_head,\n",
    "                    n_layer = n_layer,\n",
    "                    z_dim = z_dim,\n",
    "                    block_size = block_size,\n",
    "                    dropout = dropout)\n",
    "\n",
    "\n",
    "m = model.to(device)\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_state_dict = torch.load('checkpoints/checkpoint_6500.pt')\n",
    "model.load_state_dict(loaded_state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , small_data = create_subsets(dataset, [0.01])\n",
    "z, labels = process_dataset_for_z(small_data)\n",
    "z = model.sample_latent(z)\n",
    "pointer_dict = calculate_feature_pointers(z,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Slayer': 0,\n",
       " 'Judas Priest': 1,\n",
       " 'Black_sabath': 2,\n",
       " 'Pantera': 3,\n",
       " 'Ozzy Osbourne': 4,\n",
       " 'Sepultura': 5,\n",
       " 'Children Of Bodom': 6,\n",
       " 'Carcass': 7,\n",
       " 'Megadeth': 8,\n",
       " 'Type O Negative': 9,\n",
       " 'midi_pop_songs': 10,\n",
       " 'Mozart': 11,\n",
       " 'Ravel': 12,\n",
       " 'Dvorak': 13,\n",
       " 'Beethoven': 14,\n",
       " 'Haydn': 15,\n",
       " 'Schubert': 16,\n",
       " 'Cambini': 17,\n",
       " 'Bach': 18,\n",
       " 'Brahms': 19,\n",
       " 'Faure': 20}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_artist_label.artist_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16655\n"
     ]
    }
   ],
   "source": [
    "aritst = 14\n",
    "positions = torch.where(dataset[:]['labels'] == aritst)[0]\n",
    "pointer = pointer_dict['Slayer']\n",
    "magnitude = 20\n",
    "#pointer = None\n",
    "\n",
    "# Convert to a list for random sampling\n",
    "positions_list = positions.tolist()\n",
    "\n",
    "song_flag = random.sample(positions_list, 1)[0]\n",
    "\n",
    "print(song_flag)\n",
    "\n",
    "input_block_size = block_size\n",
    "\n",
    "max_new_tokens = 64\n",
    "\n",
    "gen_seed = dataset[song_flag]['input_ids'].unsqueeze(0)\n",
    "generated_sequence = model.generate(gen_seed[:input_block_size] ,max_new_tokens=max_new_tokens, latent_vector = pointer, magnitude = magnitude)\n",
    "out = generated_sequence[0].cpu().numpy().tolist()\n",
    "gen_midi = tokenizer.tokens_to_midi(out)\n",
    "gen_midi.dump('musicGPT_latent.mid')\n",
    "mixer.init()\n",
    "mixer.music.load(\"musicGPT_latent.mid\")\n",
    "mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.music.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
